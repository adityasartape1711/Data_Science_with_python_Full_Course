{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ztzCyCTq_L5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Missing Data Imputation"
      ],
      "metadata": {
        "id": "JhAUpqPHrnuE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Sample DataFrame with missing values\n",
        "data = {\n",
        "    'FeatureA': [10, 20, np.nan, 40, 50, np.nan],\n",
        "    'FeatureB': [100, 110, 120, np.nan, 140, 150],\n",
        "    'FeatureC': ['X', 'Y', 'X', 'Y', np.nan, 'Z'],\n",
        "    'FeatureD': [1, 2, 3, 4, 5, 6]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "print(\"Original DataFrame:\\n\", df)\n",
        "print(\"\\nMissing values before imputation:\\n\", df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5MkKcxqrpCv",
        "outputId": "35c6f3b5-ef7e-4de2-98bc-bbd00baa3f57"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrame:\n",
            "    FeatureA  FeatureB FeatureC  FeatureD\n",
            "0      10.0     100.0        X         1\n",
            "1      20.0     110.0        Y         2\n",
            "2       NaN     120.0        X         3\n",
            "3      40.0       NaN        Y         4\n",
            "4      50.0     140.0      NaN         5\n",
            "5       NaN     150.0        Z         6\n",
            "\n",
            "Missing values before imputation:\n",
            " FeatureA    2\n",
            "FeatureB    1\n",
            "FeatureC    1\n",
            "FeatureD    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VWzBagdarr1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "a. Complete Case Analysis (CCA)"
      ],
      "metadata": {
        "id": "k3BjTppHrz4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_cca = df.dropna()\n",
        "print(\"\\nDataFrame after Complete Case Analysis:\\n\", df_cca)\n",
        "print(\"\\nMissing values after CCA:\\n\", df_cca.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-h8FV8Br0ul",
        "outputId": "eafdb012-fc24-4dbd-a9ab-6a854a06f106"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame after Complete Case Analysis:\n",
            "    FeatureA  FeatureB FeatureC  FeatureD\n",
            "0      10.0     100.0        X         1\n",
            "1      20.0     110.0        Y         2\n",
            "\n",
            "Missing values after CCA:\n",
            " FeatureA    0\n",
            "FeatureB    0\n",
            "FeatureC    0\n",
            "FeatureD    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. Mean / Median / Mode Imputation"
      ],
      "metadata": {
        "id": "Vjzd6Qwzr6It"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean imputation for numerical feature A\n",
        "df_mean_imputed = df.copy()\n",
        "mean_feature_a = df_mean_imputed['FeatureA'].mean()\n",
        "df_mean_imputed['FeatureA'].fillna(mean_feature_a, inplace=True)\n",
        "print(\"\\nDataFrame after Mean Imputation (FeatureA):\\n\", df_mean_imputed)\n",
        "\n",
        "# Median imputation for numerical feature B\n",
        "df_median_imputed = df.copy()\n",
        "median_feature_b = df_median_imputed['FeatureB'].median()\n",
        "df_median_imputed['FeatureB'].fillna(median_feature_b, inplace=True)\n",
        "print(\"\\nDataFrame after Median Imputation (FeatureB):\\n\", df_median_imputed)\n",
        "\n",
        "# Mode imputation for categorical feature C\n",
        "df_mode_imputed = df.copy()\n",
        "mode_feature_c = df_mode_imputed['FeatureC'].mode()[0] # .mode() can return multiple if tied\n",
        "df_mode_imputed['FeatureC'].fillna(mode_feature_c, inplace=True)\n",
        "print(\"\\nDataFrame after Mode Imputation (FeatureC):\\n\", df_mode_imputed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pizrqvpnr3Gp",
        "outputId": "b71d1a82-9334-43e5-a941-a4d2d7728ebc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame after Mean Imputation (FeatureA):\n",
            "    FeatureA  FeatureB FeatureC  FeatureD\n",
            "0      10.0     100.0        X         1\n",
            "1      20.0     110.0        Y         2\n",
            "2      30.0     120.0        X         3\n",
            "3      40.0       NaN        Y         4\n",
            "4      50.0     140.0      NaN         5\n",
            "5      30.0     150.0        Z         6\n",
            "\n",
            "DataFrame after Median Imputation (FeatureB):\n",
            "    FeatureA  FeatureB FeatureC  FeatureD\n",
            "0      10.0     100.0        X         1\n",
            "1      20.0     110.0        Y         2\n",
            "2       NaN     120.0        X         3\n",
            "3      40.0     120.0        Y         4\n",
            "4      50.0     140.0      NaN         5\n",
            "5       NaN     150.0        Z         6\n",
            "\n",
            "DataFrame after Mode Imputation (FeatureC):\n",
            "    FeatureA  FeatureB FeatureC  FeatureD\n",
            "0      10.0     100.0        X         1\n",
            "1      20.0     110.0        Y         2\n",
            "2       NaN     120.0        X         3\n",
            "3      40.0       NaN        Y         4\n",
            "4      50.0     140.0        X         5\n",
            "5       NaN     150.0        Z         6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3-3309619470.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_mean_imputed['FeatureA'].fillna(mean_feature_a, inplace=True)\n",
            "/tmp/ipython-input-3-3309619470.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_median_imputed['FeatureB'].fillna(median_feature_b, inplace=True)\n",
            "/tmp/ipython-input-3-3309619470.py:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_mode_imputed['FeatureC'].fillna(mode_feature_c, inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "c. Random Sample Imputation"
      ],
      "metadata": {
        "id": "ELU3HFsrsPpe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_random_imputed = df.copy()\n",
        "random_sample_a = df_random_imputed['FeatureA'].dropna().sample(df_random_imputed['FeatureA'].isnull().sum(), random_state=42)\n",
        "random_sample_a.index = df_random_imputed[df_random_imputed['FeatureA'].isnull()].index\n",
        "df_random_imputed.loc[df_random_imputed['FeatureA'].isnull(), 'FeatureA'] = random_sample_a\n",
        "print(\"\\nDataFrame after Random Sample Imputation (FeatureA):\\n\", df_random_imputed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aihFO-MFr9ol",
        "outputId": "6e9bf681-aa1c-476a-cc2d-674ba96f43db"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame after Random Sample Imputation (FeatureA):\n",
            "    FeatureA  FeatureB FeatureC  FeatureD\n",
            "0      10.0     100.0        X         1\n",
            "1      20.0     110.0        Y         2\n",
            "2      20.0     120.0        X         3\n",
            "3      40.0       NaN        Y         4\n",
            "4      50.0     140.0      NaN         5\n",
            "5      50.0     150.0        Z         6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HH5CMFs4sSFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "d. Replacement by Arbitrary Value"
      ],
      "metadata": {
        "id": "ZVG_vgRSsVHZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_arbitrary_imputed = df.copy()\n",
        "df_arbitrary_imputed['FeatureA'].fillna(-99, inplace=True)\n",
        "print(\"\\nDataFrame after Arbitrary Value Imputation (FeatureA with -99):\\n\", df_arbitrary_imputed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMXHslDbsVmN",
        "outputId": "1ce66bb6-8366-4cbe-a772-177c360e1452"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame after Arbitrary Value Imputation (FeatureA with -99):\n",
            "    FeatureA  FeatureB FeatureC  FeatureD\n",
            "0      10.0     100.0        X         1\n",
            "1      20.0     110.0        Y         2\n",
            "2     -99.0     120.0        X         3\n",
            "3      40.0       NaN        Y         4\n",
            "4      50.0     140.0      NaN         5\n",
            "5     -99.0     150.0        Z         6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-5-3019250852.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_arbitrary_imputed['FeatureA'].fillna(-99, inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "e. Missing Value Indicator"
      ],
      "metadata": {
        "id": "4CxGHMV9sc62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_indicator = df.copy()\n",
        "df_indicator['FeatureA_is_missing'] = df_indicator['FeatureA'].isnull().astype(int)\n",
        "# Then apply another imputation method (e.g., mean) for FeatureA\n",
        "df_indicator['FeatureA'].fillna(df_indicator['FeatureA'].mean(), inplace=True)\n",
        "print(\"\\nDataFrame with Missing Value Indicator (FeatureA):\\n\", df_indicator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oh2Hlb6esXsa",
        "outputId": "89cb0d62-8eda-4e69-c2ca-9a90f5ad5967"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame with Missing Value Indicator (FeatureA):\n",
            "    FeatureA  FeatureB FeatureC  FeatureD  FeatureA_is_missing\n",
            "0      10.0     100.0        X         1                    0\n",
            "1      20.0     110.0        Y         2                    0\n",
            "2      30.0     120.0        X         3                    1\n",
            "3      40.0       NaN        Y         4                    0\n",
            "4      50.0     140.0      NaN         5                    0\n",
            "5      30.0     150.0        Z         6                    1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-6-3070081831.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_indicator['FeatureA'].fillna(df_indicator['FeatureA'].mean(), inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "f. Multivariate Imputation (e.g., using IterativeImputer)"
      ],
      "metadata": {
        "id": "c5hiKWQ0slKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.experimental import enable_iterative_imputer # Required for IterativeImputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "\n",
        "# Create a fresh copy, as IterativeImputer works on numerical data\n",
        "df_multi_impute = df[['FeatureA', 'FeatureB', 'FeatureD']].copy()\n",
        "print(\"\\nDataFrame for Multivariate Imputation:\\n\", df_multi_impute)\n",
        "\n",
        "imputer = IterativeImputer(max_iter=10, random_state=0)\n",
        "imputed_data = imputer.fit_transform(df_multi_impute)\n",
        "df_multi_imputed = pd.DataFrame(imputed_data, columns=df_multi_impute.columns)\n",
        "print(\"\\nDataFrame after Multivariate Imputation:\\n\", df_multi_imputed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FGJQudLsffQ",
        "outputId": "dcbdca8d-4f28-4914-c3ba-6d913eb0bc9f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame for Multivariate Imputation:\n",
            "    FeatureA  FeatureB  FeatureD\n",
            "0      10.0     100.0         1\n",
            "1      20.0     110.0         2\n",
            "2       NaN     120.0         3\n",
            "3      40.0       NaN         4\n",
            "4      50.0     140.0         5\n",
            "5       NaN     150.0         6\n",
            "\n",
            "DataFrame after Multivariate Imputation:\n",
            "     FeatureA   FeatureB  FeatureD\n",
            "0  10.000000  100.00000       1.0\n",
            "1  20.000000  110.00000       2.0\n",
            "2  29.998373  120.00000       3.0\n",
            "3  40.000000  130.00678       4.0\n",
            "4  50.000000  140.00000       5.0\n",
            "5  59.996419  150.00000       6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Handling Outliers"
      ],
      "metadata": {
        "id": "NKnJ7YU6steK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample DataFrame with outliers\n",
        "data_outlier = {'Value': [10, 12, 11, 15, 13, 120, 14, 16, 8, 500]}\n",
        "df_outlier = pd.DataFrame(data_outlier)\n",
        "print(\"\\nOriginal DataFrame with outliers:\\n\", df_outlier)\n",
        "\n",
        "# A simple way to identify outliers (e.g., using IQR method)\n",
        "Q1 = df_outlier['Value'].quantile(0.25)\n",
        "Q3 = df_outlier['Value'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "print(f\"Q1: {Q1}, Q3: {Q3}, IQR: {IQR}\")\n",
        "print(f\"Lower Bound (Outlier): {lower_bound}, Upper Bound (Outlier): {upper_bound}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDDhawaZsoEb",
        "outputId": "b062849d-bda8-4f88-cdc2-6ce8eb64ff38"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original DataFrame with outliers:\n",
            "    Value\n",
            "0     10\n",
            "1     12\n",
            "2     11\n",
            "3     15\n",
            "4     13\n",
            "5    120\n",
            "6     14\n",
            "7     16\n",
            "8      8\n",
            "9    500\n",
            "Q1: 11.25, Q3: 15.75, IQR: 4.5\n",
            "Lower Bound (Outlier): 4.5, Upper Bound (Outlier): 22.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "a. Removing Outliers"
      ],
      "metadata": {
        "id": "wVRjMYZBszA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_outlier_removed = df_outlier[(df_outlier['Value'] >= lower_bound) & (df_outlier['Value'] <= upper_bound)].copy()\n",
        "print(\"\\nDataFrame after Removing Outliers:\\n\", df_outlier_removed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IgnlAn5swIm",
        "outputId": "6896c361-1df4-4a0e-81f8-8b881e53d800"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame after Removing Outliers:\n",
            "    Value\n",
            "0     10\n",
            "1     12\n",
            "2     11\n",
            "3     15\n",
            "4     13\n",
            "6     14\n",
            "7     16\n",
            "8      8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qSoECSyYs1iG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. Treating Outliers as NaN"
      ],
      "metadata": {
        "id": "o4C_3Giys5rf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_outlier_to_nan = df_outlier.copy()\n",
        "df_outlier_to_nan.loc[(df_outlier_to_nan['Value'] < lower_bound) | (df_outlier_to_nan['Value'] > upper_bound), 'Value'] = np.nan\n",
        "print(\"\\nDataFrame after Treating Outliers as NaN:\\n\", df_outlier_to_nan)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NXcs7cZs6LQ",
        "outputId": "36a9792d-305a-47db-f2e1-9d2094d7c91c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame after Treating Outliers as NaN:\n",
            "    Value\n",
            "0   10.0\n",
            "1   12.0\n",
            "2   11.0\n",
            "3   15.0\n",
            "4   13.0\n",
            "5    NaN\n",
            "6   14.0\n",
            "7   16.0\n",
            "8    8.0\n",
            "9    NaN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fta6cLy0s8OZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "c. Capping, Winsorization"
      ],
      "metadata": {
        "id": "kYYLp10ls_Wt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_outlier_capped = df_outlier.copy()\n",
        "df_outlier_capped['Value'] = np.where(df_outlier_capped['Value'] < lower_bound, lower_bound, df_outlier_capped['Value'])\n",
        "df_outlier_capped['Value'] = np.where(df_outlier_capped['Value'] > upper_bound, upper_bound, df_outlier_capped['Value'])\n",
        "print(\"\\nDataFrame after Capping Outliers (using IQR bounds):\\n\", df_outlier_capped)\n",
        "\n",
        "# Example using percentiles\n",
        "upper_cap_percentile = df_outlier['Value'].quantile(0.95)\n",
        "lower_cap_percentile = df_outlier['Value'].quantile(0.05)\n",
        "df_outlier_winsorized = df_outlier.copy()\n",
        "df_outlier_winsorized['Value'] = np.where(df_outlier_winsorized['Value'] > upper_cap_percentile, upper_cap_percentile, df_outlier_winsorized['Value'])\n",
        "df_outlier_winsorized['Value'] = np.where(df_outlier_winsorized['Value'] < lower_cap_percentile, lower_cap_percentile, df_outlier_winsorized['Value'])\n",
        "print(\"\\nDataFrame after Winsorization (using 5th & 95th percentile):\\n\", df_outlier_winsorized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "km1akaWds_0R",
        "outputId": "b441fdbc-4752-412b-fb2f-aae66e042c0b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame after Capping Outliers (using IQR bounds):\n",
            "    Value\n",
            "0   10.0\n",
            "1   12.0\n",
            "2   11.0\n",
            "3   15.0\n",
            "4   13.0\n",
            "5   22.5\n",
            "6   14.0\n",
            "7   16.0\n",
            "8    8.0\n",
            "9   22.5\n",
            "\n",
            "DataFrame after Winsorization (using 5th & 95th percentile):\n",
            "    Value\n",
            "0   10.0\n",
            "1   12.0\n",
            "2   11.0\n",
            "3   15.0\n",
            "4   13.0\n",
            "5  120.0\n",
            "6   14.0\n",
            "7   16.0\n",
            "8    8.9\n",
            "9  329.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Data Transformation & Binning"
      ],
      "metadata": {
        "id": "g8kun8NatGWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample DataFrame for transformations\n",
        "data_transform = {\n",
        "    'Numerical': [1, 5, 10, 20, 50, 100, 200, 500, 1000],\n",
        "    'Category': ['Red', 'Blue', 'Green', 'Red', 'Blue', 'Red', 'Green', 'Blue', 'Red'],\n",
        "    'Ordinal': ['Low', 'Medium', 'High', 'Medium', 'Low', 'High', 'Medium', 'Low', 'High'],\n",
        "    'DateCol': pd.to_datetime(['2023-01-01', '2023-01-15', '2023-02-01', '2023-03-10', '2023-04-20', '2023-05-05', '2023-06-12', '2023-07-25', '2023-08-30']),\n",
        "    'TransactionAmount': [100, 150, 10, 200, 120, 50, 80, 300, 180],\n",
        "    'CustomerID': ['C1', 'C2', 'C1', 'C3', 'C2', 'C1', 'C3', 'C2', 'C1']\n",
        "}\n",
        "df_transform = pd.DataFrame(data_transform)\n",
        "print(\"\\nOriginal DataFrame for transformations:\\n\", df_transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqLzS11GtCLY",
        "outputId": "0e95aaf8-4e88-497b-acd6-cbb4854c8bdc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original DataFrame for transformations:\n",
            "    Numerical Category Ordinal    DateCol  TransactionAmount CustomerID\n",
            "0          1      Red     Low 2023-01-01                100         C1\n",
            "1          5     Blue  Medium 2023-01-15                150         C2\n",
            "2         10    Green    High 2023-02-01                 10         C1\n",
            "3         20      Red  Medium 2023-03-10                200         C3\n",
            "4         50     Blue     Low 2023-04-20                120         C2\n",
            "5        100      Red    High 2023-05-05                 50         C1\n",
            "6        200    Green  Medium 2023-06-12                 80         C3\n",
            "7        500     Blue     Low 2023-07-25                300         C2\n",
            "8       1000      Red    High 2023-08-30                180         C1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HBz4_NpAtJC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "a. Binning (Discretization)"
      ],
      "metadata": {
        "id": "dAiLdPz-tNyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Equal Frequency Binning (using qcut)\n",
        "df_transform['Numerical_EqualFreq_Bins'] = pd.qcut(df_transform['Numerical'], q=3, labels=['Low', 'Medium', 'High'])\n",
        "print(\"\\nEqual Frequency Binning (Numerical):\\n\", df_transform[['Numerical', 'Numerical_EqualFreq_Bins']])\n",
        "\n",
        "# Equal Length Binning (using cut)\n",
        "df_transform['Numerical_EqualLen_Bins'] = pd.cut(df_transform['Numerical'], bins=3, labels=['Bin1', 'Bin2', 'Bin3'])\n",
        "print(\"\\nEqual Length Binning (Numerical):\\n\", df_transform[['Numerical', 'Numerical_EqualLen_Bins']])\n",
        "\n",
        "# Note: Discretization with Trees/ChiMerge often requires a target variable\n",
        "# and custom implementations or specific libraries.\n",
        "# Example with KBinsDiscretizer (can do 'uniform' for equal-width, 'quantile' for equal-frequency)\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "numerical_data = df_transform[['Numerical']]\n",
        "est = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform') # or 'quantile'\n",
        "df_transform['Numerical_KBins_Uniform'] = est.fit_transform(numerical_data)\n",
        "print(\"\\nKBinsDiscretizer (uniform strategy):\\n\", df_transform[['Numerical', 'Numerical_KBins_Uniform']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7m8wtwc5tOVL",
        "outputId": "30f2888d-5089-4d06-a10f-d9141e0a910c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Equal Frequency Binning (Numerical):\n",
            "    Numerical Numerical_EqualFreq_Bins\n",
            "0          1                      Low\n",
            "1          5                      Low\n",
            "2         10                      Low\n",
            "3         20                   Medium\n",
            "4         50                   Medium\n",
            "5        100                   Medium\n",
            "6        200                     High\n",
            "7        500                     High\n",
            "8       1000                     High\n",
            "\n",
            "Equal Length Binning (Numerical):\n",
            "    Numerical Numerical_EqualLen_Bins\n",
            "0          1                    Bin1\n",
            "1          5                    Bin1\n",
            "2         10                    Bin1\n",
            "3         20                    Bin1\n",
            "4         50                    Bin1\n",
            "5        100                    Bin1\n",
            "6        200                    Bin1\n",
            "7        500                    Bin2\n",
            "8       1000                    Bin3\n",
            "\n",
            "KBinsDiscretizer (uniform strategy):\n",
            "    Numerical  Numerical_KBins_Uniform\n",
            "0          1                      0.0\n",
            "1          5                      0.0\n",
            "2         10                      0.0\n",
            "3         20                      0.0\n",
            "4         50                      0.0\n",
            "5        100                      0.0\n",
            "6        200                      0.0\n",
            "7        500                      1.0\n",
            "8       1000                      2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Om56rIUctRLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. Log Transform"
      ],
      "metadata": {
        "id": "ZqxKsWPrtVzk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_transform['Numerical_Log'] = np.log(df_transform['Numerical'])\n",
        "print(\"\\nLog Transform (Numerical):\\n\", df_transform[['Numerical', 'Numerical_Log']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wSknnY8tWbb",
        "outputId": "5a5cf3b7-7c53-4605-e67f-dc36ceb89b47"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Log Transform (Numerical):\n",
            "    Numerical  Numerical_Log\n",
            "0          1       0.000000\n",
            "1          5       1.609438\n",
            "2         10       2.302585\n",
            "3         20       2.995732\n",
            "4         50       3.912023\n",
            "5        100       4.605170\n",
            "6        200       5.298317\n",
            "7        500       6.214608\n",
            "8       1000       6.907755\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xdqgt21mtYfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "c. Categorical Encoding"
      ],
      "metadata": {
        "id": "LONjJwHFtbIl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One Hot Encoding"
      ],
      "metadata": {
        "id": "XjFZmpWzte0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_one_hot = pd.get_dummies(df_transform['Category'], prefix='Category')\n",
        "df_encoded = pd.concat([df_transform, df_one_hot], axis=1)\n",
        "print(\"\\nOne Hot Encoding (Category):\\n\", df_encoded[['Category', 'Category_Blue', 'Category_Green', 'Category_Red']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AXddwx3tfS9",
        "outputId": "7cae83e6-79e6-49b9-ba2a-0d1c508afe5b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "One Hot Encoding (Category):\n",
            "   Category  Category_Blue  Category_Green  Category_Red\n",
            "0      Red          False           False          True\n",
            "1     Blue           True           False         False\n",
            "2    Green          False            True         False\n",
            "3      Red          False           False          True\n",
            "4     Blue           True           False         False\n",
            "5      Red          False           False          True\n",
            "6    Green          False            True         False\n",
            "7     Blue           True           False         False\n",
            "8      Red          False           False          True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4plto_tBtkO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Count and Frequency Encoding"
      ],
      "metadata": {
        "id": "CPLmwHyXtnf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count_map = df_transform['Category'].value_counts().to_dict()\n",
        "df_transform['Category_Count'] = df_transform['Category'].map(count_map)\n",
        "\n",
        "freq_map = df_transform['Category'].value_counts(normalize=True).to_dict()\n",
        "df_transform['Category_Frequency'] = df_transform['Category'].map(freq_map)\n",
        "print(\"\\nCount and Frequency Encoding (Category):\\n\", df_transform[['Category', 'Category_Count', 'Category_Frequency']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AEyhyOVtn9w",
        "outputId": "5bad3d2c-b799-4b33-e695-5f1e7b0abd7f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Count and Frequency Encoding (Category):\n",
            "   Category  Category_Count  Category_Frequency\n",
            "0      Red               4            0.444444\n",
            "1     Blue               3            0.333333\n",
            "2    Green               2            0.222222\n",
            "3      Red               4            0.444444\n",
            "4     Blue               3            0.333333\n",
            "5      Red               4            0.444444\n",
            "6    Green               2            0.222222\n",
            "7     Blue               3            0.333333\n",
            "8      Red               4            0.444444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Target Encoding/Mean Encoding (with proper precautions)"
      ],
      "metadata": {
        "id": "8GpsSfbut-do"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Conceptual example, requires a target variable (e.g., 'Target' column)\n",
        "# from category_encoders import TargetEncoder\n",
        "# encoder = TargetEncoder(cols=['Category'])\n",
        "# df_encoded_target = encoder.fit_transform(df_transform['Category'], df_transform['Target'])\n",
        "print(\"\\nTarget Encoding (Conceptual): Replaces category with mean of target for that category. Requires a target variable.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCS8vRKntqMz",
        "outputId": "0305f79b-8a94-4063-84e1-193121f960da"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Target Encoding (Conceptual): Replaces category with mean of target for that category. Requires a target variable.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ordinal Encoding"
      ],
      "metadata": {
        "id": "hH5yiEdZuGwP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "ordinal_map = {'Low': 0, 'Medium': 1, 'High': 2}\n",
        "df_transform['Ordinal_Encoded'] = df_transform['Ordinal'].map(ordinal_map)\n",
        "print(\"\\nOrdinal Encoding (Ordinal):\\n\", df_transform[['Ordinal', 'Ordinal_Encoded']])\n",
        "\n",
        "# Or using sklearn's OrdinalEncoder (infers order or takes categories)\n",
        "encoder = OrdinalEncoder(categories=[['Low', 'Medium', 'High']])\n",
        "df_transform['Ordinal_Encoded_Sklearn'] = encoder.fit_transform(df_transform[['Ordinal']])\n",
        "print(\"\\nOrdinal Encoding (Ordinal) with Sklearn:\\n\", df_transform[['Ordinal', 'Ordinal_Encoded_Sklearn']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NtLAcnQtzap",
        "outputId": "61dbd0b9-f9eb-4b2f-f970-6855e13c2c74"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ordinal Encoding (Ordinal):\n",
            "   Ordinal  Ordinal_Encoded\n",
            "0     Low                0\n",
            "1  Medium                1\n",
            "2    High                2\n",
            "3  Medium                1\n",
            "4     Low                0\n",
            "5    High                2\n",
            "6  Medium                1\n",
            "7     Low                0\n",
            "8    High                2\n",
            "\n",
            "Ordinal Encoding (Ordinal) with Sklearn:\n",
            "   Ordinal  Ordinal_Encoded_Sklearn\n",
            "0     Low                      0.0\n",
            "1  Medium                      1.0\n",
            "2    High                      2.0\n",
            "3  Medium                      1.0\n",
            "4     Low                      0.0\n",
            "5    High                      2.0\n",
            "6  Medium                      1.0\n",
            "7     Low                      0.0\n",
            "8    High                      2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Weight of Evidence (WoE)"
      ],
      "metadata": {
        "id": "zv3a1tgWuMJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# WoE = ln( (% of non-events in category) / (% of events in category) )\n",
        "print(\"\\nWeight of Evidence (WoE) Encoding (Conceptual): Useful for binary classification. Replaces category with a value reflecting its predictive power towards the target.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XumlN0vhuJce",
        "outputId": "57e00754-7bdc-4454-b01f-5993259bceb6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Weight of Evidence (WoE) Encoding (Conceptual): Useful for binary classification. Replaces category with a value reflecting its predictive power towards the target.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rare Label Encoding"
      ],
      "metadata": {
        "id": "qeyJs8tcuS-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 0.05 # 5% frequency\n",
        "value_counts = df_transform['Category'].value_counts(normalize=True)\n",
        "rare_labels = value_counts[value_counts < threshold].index\n",
        "df_transform['Category_RareHandled'] = np.where(df_transform['Category'].isin(rare_labels), 'Rare', df_transform['Category'])\n",
        "print(\"\\nRare Label Encoding (Category):\\n\", df_transform[['Category', 'Category_RareHandled']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbhbIIG3uOjR",
        "outputId": "c93b4ebb-6482-40e9-809d-5ee08e039301"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Rare Label Encoding (Category):\n",
            "   Category Category_RareHandled\n",
            "0      Red                  Red\n",
            "1     Blue                 Blue\n",
            "2    Green                Green\n",
            "3      Red                  Red\n",
            "4     Blue                 Blue\n",
            "5      Red                  Red\n",
            "6    Green                Green\n",
            "7     Blue                 Blue\n",
            "8      Red                  Red\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BaseN, Feature Hashing and others (brief overview)"
      ],
      "metadata": {
        "id": "QHWQVo3tuYXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from category_encoders import HashingEncoder\n",
        "# encoder = HashingEncoder(n_components=8) # Map to 8 new features\n",
        "# df_hashed = encoder.fit_transform(df_transform['Category'])\n",
        "print(\"\\nBaseN/Feature Hashing (Conceptual): Advanced techniques for high-cardinality categoricals, balancing memory/speed with interpretability tradeoffs.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXX8toh1uVYS",
        "outputId": "78cdccb1-d780-450a-a057-12ab51c66374"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "BaseN/Feature Hashing (Conceptual): Advanced techniques for high-cardinality categoricals, balancing memory/speed with interpretability tradeoffs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "d. Grouping Operations"
      ],
      "metadata": {
        "id": "Z-d_fD5sufdp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Mean transaction amount per customer\n",
        "df_transform['AvgTransaction_by_Customer'] = df_transform.groupby('CustomerID')['TransactionAmount'].transform('mean')\n",
        "print(\"\\nGrouping Operation (Avg Transaction by Customer):\\n\", df_transform[['CustomerID', 'TransactionAmount', 'AvgTransaction_by_Customer']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H00DVN6Lua9M",
        "outputId": "67199549-8a5b-41ee-fdc3-5c55e1a3f3bd"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Grouping Operation (Avg Transaction by Customer):\n",
            "   CustomerID  TransactionAmount  AvgTransaction_by_Customer\n",
            "0         C1                100                        85.0\n",
            "1         C2                150                       190.0\n",
            "2         C1                 10                        85.0\n",
            "3         C3                200                       140.0\n",
            "4         C2                120                       190.0\n",
            "5         C1                 50                        85.0\n",
            "6         C3                 80                       140.0\n",
            "7         C2                300                       190.0\n",
            "8         C1                180                        85.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "e. Feature Split"
      ],
      "metadata": {
        "id": "mnysgNEsumTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_split = pd.DataFrame({'ProductCode': ['A-Red-Small', 'B-Blue-Medium', 'A-Green-Large']})\n",
        "df_split[['Product_Type', 'Product_Color', 'Product_Size']] = df_split['ProductCode'].str.split('-', expand=True)\n",
        "print(\"\\nFeature Split (ProductCode):\\n\", df_split)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymyqByycuhxZ",
        "outputId": "b3f4cc81-8946-4828-c91f-4c2cce7e03ad"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Feature Split (ProductCode):\n",
            "      ProductCode Product_Type Product_Color Product_Size\n",
            "0    A-Red-Small            A           Red        Small\n",
            "1  B-Blue-Medium            B          Blue       Medium\n",
            "2  A-Green-Large            A         Green        Large\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "f. Date and Time Engineering"
      ],
      "metadata": {
        "id": "brDUVojBuryN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_transform['Year'] = df_transform['DateCol'].dt.year\n",
        "df_transform['Month'] = df_transform['DateCol'].dt.month\n",
        "df_transform['Day'] = df_transform['DateCol'].dt.day\n",
        "df_transform['DayOfWeek'] = df_transform['DateCol'].dt.dayofweek # Monday=0, Sunday=6\n",
        "df_transform['DayOfYear'] = df_transform['DateCol'].dt.dayofyear\n",
        "df_transform['WeekOfYear'] = df_transform['DateCol'].dt.isocalendar().week.astype(int)\n",
        "df_transform['Quarter'] = df_transform['DateCol'].dt.quarter\n",
        "# Time elapsed since a reference date\n",
        "reference_date = pd.to_datetime('2023-01-01')\n",
        "df_transform['Days_Since_Ref'] = (df_transform['DateCol'] - reference_date).dt.days\n",
        "print(\"\\nDate and Time Engineering (DateCol):\\n\", df_transform[['DateCol', 'Year', 'Month', 'Day', 'DayOfWeek', 'WeekOfYear', 'Days_Since_Ref']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCZDHgHquozS",
        "outputId": "ffb409fd-c36f-4f38-a640-bb123521e1ea"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Date and Time Engineering (DateCol):\n",
            "      DateCol  Year  Month  Day  DayOfWeek  WeekOfYear  Days_Since_Ref\n",
            "0 2023-01-01  2023      1    1          6          52               0\n",
            "1 2023-01-15  2023      1   15          6           2              14\n",
            "2 2023-02-01  2023      2    1          2           5              31\n",
            "3 2023-03-10  2023      3   10          4          10              68\n",
            "4 2023-04-20  2023      4   20          3          16             109\n",
            "5 2023-05-05  2023      5    5          4          18             124\n",
            "6 2023-06-12  2023      6   12          0          24             162\n",
            "7 2023-07-25  2023      7   25          1          30             205\n",
            "8 2023-08-30  2023      8   30          2          35             241\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "g. Feature Creation (Arithmetic Operations)"
      ],
      "metadata": {
        "id": "NpSvci6zux_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_arithmetic = pd.DataFrame({\n",
        "    'FeatureX': [10, 20, 30, 40],\n",
        "    'FeatureY': [2, 4, 5, 8],\n",
        "    'Amount1': [100, 200, 50, 150],\n",
        "    'Amount2': [20, 40, 10, 30]\n",
        "})\n",
        "\n",
        "df_arithmetic['Sum_XY'] = df_arithmetic['FeatureX'] + df_arithmetic['FeatureY']\n",
        "df_arithmetic['Ratio_XY'] = df_arithmetic['FeatureX'] / df_arithmetic['FeatureY']\n",
        "df_arithmetic['Product_Amounts'] = df_arithmetic['Amount1'] * df_arithmetic['Amount2']\n",
        "\n",
        "# Aggregating Transaction Data: Feature over time window (conceptual)\n",
        "# This would typically involve time-series data and rolling windows.\n",
        "# df_transactions['rolling_avg_7d'] = df_transactions['transaction_value'].rolling('7D').mean()\n",
        "\n",
        "print(\"\\nFeature Creation (Arithmetic Operations):\\n\", df_arithmetic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aihNz_SKuujD",
        "outputId": "b192440c-9025-436f-8c6f-3db36a988d8e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Feature Creation (Arithmetic Operations):\n",
            "    FeatureX  FeatureY  Amount1  Amount2  Sum_XY  Ratio_XY  Product_Amounts\n",
            "0        10         2      100       20      12       5.0             2000\n",
            "1        20         4      200       40      24       5.0             8000\n",
            "2        30         5       50       10      35       6.0              500\n",
            "3        40         8      150       30      48       5.0             4500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "h. Variable Transformation (Mathematical Functions)"
      ],
      "metadata": {
        "id": "_ByfhiUBu1qm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import boxcox, yeojohnson\n",
        "# Ensure 'Numerical' feature doesn't have zeros or negative for log/sqrt\n",
        "# df_transform['Numerical'] = df_transform['Numerical'] + 1 # Add 1 to handle 0 for log\n",
        "\n",
        "df_transform['Numerical_Reciprocal'] = 1 / df_transform['Numerical']\n",
        "df_transform['Numerical_SquareRoot'] = np.sqrt(df_transform['Numerical'])\n",
        "df_transform['Numerical_Exponential'] = np.exp(df_transform['Numerical'])\n",
        "\n",
        "# Box-Cox and Yeo-Johnson require positive values for Box-Cox\n",
        "# For Box-Cox, data must be strictly positive.\n",
        "# For Yeo-Johnson, data can contain zero or negative values.\n",
        "transformed_boxcox, lambda_boxcox = boxcox(df_transform['Numerical'])\n",
        "df_transform['Numerical_BoxCox'] = transformed_boxcox\n",
        "\n",
        "transformed_yeojohnson, lambda_yeojohnson = yeojohnson(df_transform['Numerical'])\n",
        "df_transform['Numerical_YeoJohnson'] = transformed_yeojohnson\n",
        "\n",
        "print(\"\\nVariable Transformations (Numerical):\\n\", df_transform[['Numerical', 'Numerical_Reciprocal', 'Numerical_SquareRoot', 'Numerical_Exponential', 'Numerical_BoxCox', 'Numerical_YeoJohnson']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kCRl10vu0r8",
        "outputId": "9b3d83d1-d0bd-486b-e581-745536f08432"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Variable Transformations (Numerical):\n",
            "    Numerical  Numerical_Reciprocal  Numerical_SquareRoot  \\\n",
            "0          1                 1.000              1.000000   \n",
            "1          5                 0.200              2.236068   \n",
            "2         10                 0.100              3.162278   \n",
            "3         20                 0.050              4.472136   \n",
            "4         50                 0.020              7.071068   \n",
            "5        100                 0.010             10.000000   \n",
            "6        200                 0.005             14.142136   \n",
            "7        500                 0.002             22.360680   \n",
            "8       1000                 0.001             31.622777   \n",
            "\n",
            "   Numerical_Exponential  Numerical_BoxCox  Numerical_YeoJohnson  \n",
            "0           2.718282e+00          0.000000              0.694560  \n",
            "1           1.484132e+02          1.676720              1.801218  \n",
            "2           2.202647e+04          2.441945              2.414856  \n",
            "3           4.851652e+08          3.234457              3.071898  \n",
            "4           5.184706e+21          4.325639              3.977563  \n",
            "5           2.688117e+43          5.185324              4.678222  \n",
            "6           7.225974e+86          6.075665              5.386741  \n",
            "7          1.403592e+217          7.301543              6.331460  \n",
            "8                    inf          8.267347              7.050801  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Feature Scaling"
      ],
      "metadata": {
        "id": "H_d-3OHUu9wW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler, Normalizer\n",
        "\n",
        "data_scale = {'Feature1': [10, 200, 30, 500, 100], 'Feature2': [0.1, 0.5, 0.2, 0.8, 0.3]}\n",
        "df_scale = pd.DataFrame(data_scale)\n",
        "print(\"\\nOriginal DataFrame for Scaling:\\n\", df_scale)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tg2pcmGWu5xP",
        "outputId": "af410119-47f5-4442-95a3-33dd0386c908"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original DataFrame for Scaling:\n",
            "    Feature1  Feature2\n",
            "0        10       0.1\n",
            "1       200       0.5\n",
            "2        30       0.2\n",
            "3       500       0.8\n",
            "4       100       0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "a. Standardization (Z-score Normalization)"
      ],
      "metadata": {
        "id": "FKb_Zy-wvDex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "df_scale_standardized = pd.DataFrame(scaler.fit_transform(df_scale), columns=df_scale.columns)\n",
        "print(\"\\nDataFrame after Standardization:\\n\", df_scale_standardized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsEK-2Q2vAg9",
        "outputId": "070b6b54-7c1c-4020-9cdd-b92ecf83cf95"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame after Standardization:\n",
            "    Feature1  Feature2\n",
            "0 -0.883578 -1.128152\n",
            "1  0.178953  0.483494\n",
            "2 -0.771733 -0.725241\n",
            "3  1.856633  1.692228\n",
            "4 -0.380274 -0.322329\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. MinMax Scaling"
      ],
      "metadata": {
        "id": "EVbIyjc-vJ-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "df_scale_minmax = pd.DataFrame(scaler.fit_transform(df_scale), columns=df_scale.columns)\n",
        "print(\"\\nDataFrame after MinMax Scaling (to 0-1):\\n\", df_scale_minmax)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmXB--csvF4R",
        "outputId": "4bfa64be-f64c-4679-c68c-70c1196d48d8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame after MinMax Scaling (to 0-1):\n",
            "    Feature1  Feature2\n",
            "0  0.000000  0.000000\n",
            "1  0.387755  0.571429\n",
            "2  0.040816  0.142857\n",
            "3  1.000000  1.000000\n",
            "4  0.183673  0.285714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "c. Mean Scaling"
      ],
      "metadata": {
        "id": "F6wyzx5KvO3S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_scale_mean = df_scale.copy()\n",
        "df_scale_mean['Feature1'] = df_scale_mean['Feature1'] - df_scale_mean['Feature1'].mean()\n",
        "df_scale_mean['Feature2'] = df_scale_mean['Feature2'] - df_scale_mean['Feature2'].mean()\n",
        "print(\"\\nDataFrame after Mean Scaling:\\n\", df_scale_mean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_7g2K_7vMXU",
        "outputId": "fc74f03a-4383-4e2d-c8cd-1367e562976b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame after Mean Scaling:\n",
            "    Feature1  Feature2\n",
            "0    -158.0     -0.28\n",
            "1      32.0      0.12\n",
            "2    -138.0     -0.18\n",
            "3     332.0      0.42\n",
            "4     -68.0     -0.08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "d. Max Absolute Scaling"
      ],
      "metadata": {
        "id": "v9gcJOGavUEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MaxAbsScaler()\n",
        "df_scale_maxabs = pd.DataFrame(scaler.fit_transform(df_scale), columns=df_scale.columns)\n",
        "print(\"\\nDataFrame after Max Absolute Scaling:\\n\", df_scale_maxabs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9xcDPj9vRRh",
        "outputId": "5d4b99ea-f8d4-4069-a1d1-b76e25ee53c1"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame after Max Absolute Scaling:\n",
            "    Feature1  Feature2\n",
            "0      0.02     0.125\n",
            "1      0.40     0.625\n",
            "2      0.06     0.250\n",
            "3      1.00     1.000\n",
            "4      0.20     0.375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "e. Unit Norm-Scaling (Normalization)"
      ],
      "metadata": {
        "id": "iPp1qEsEvatZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = Normalizer(norm='l2') # or 'l1'\n",
        "df_scale_unitnorm = pd.DataFrame(scaler.fit_transform(df_scale), columns=df_scale.columns)\n",
        "print(\"\\nDataFrame after Unit Norm Scaling (L2):\\n\", df_scale_unitnorm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oo_s6E2UvWXX",
        "outputId": "e80dc7aa-90ef-4324-c970-9947edb6494c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame after Unit Norm Scaling (L2):\n",
            "    Feature1  Feature2\n",
            "0  0.999950  0.010000\n",
            "1  0.999997  0.002500\n",
            "2  0.999978  0.006667\n",
            "3  0.999999  0.001600\n",
            "4  0.999996  0.003000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Feature Selection Methods"
      ],
      "metadata": {
        "id": "OjD-zJ0uvgVe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.feature_selection import SelectKBest, chi2, f_classif\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_selection import RFE\n",
        "\n",
        "# Create a synthetic dataset\n",
        "X, y = make_classification(n_samples=100, n_features=10, n_informative=5, n_redundant=2, random_state=42)\n",
        "df_fs = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(10)])\n",
        "df_fs['target'] = y\n",
        "print(\"\\nSynthetic Dataset for Feature Selection (first 5 rows):\\n\", df_fs.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KyN945SvdNd",
        "outputId": "e49d55d9-ef3f-4e31-ad62-529a2a5deb55"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Synthetic Dataset for Feature Selection (first 5 rows):\n",
            "    feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
            "0  -0.149037   3.639790  -4.772025  -0.006653  -1.712937  -2.745894   \n",
            "1   2.643572   2.247720   0.269296  -0.202846   2.757147   2.674546   \n",
            "2   0.343135  -0.945760   0.557920   1.323875  -1.249062   2.291925   \n",
            "3  -0.300360  -1.511354  -0.632684  -0.804787  -1.254642   2.184507   \n",
            "4  -0.798439   3.013817   0.664099   1.341312   2.697771   0.022003   \n",
            "\n",
            "   feature_6  feature_7  feature_8  feature_9  target  \n",
            "0  -1.024823   4.487371  -1.125419  -1.014853       0  \n",
            "1  -2.024225   0.301308   0.180531   1.455804       0  \n",
            "2  -0.744303  -0.262295   1.205628  -0.725942       1  \n",
            "3  -0.436571  -0.967546   0.793658  -0.217025       0  \n",
            "4   0.633598   0.667231  -1.524015  -1.111219       1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "a. Filter Methods"
      ],
      "metadata": {
        "id": "-4JMbdpSvm_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chi-Square Test (for non-negative features, typically categorical or binned numerical)\n",
        "# Assuming some features are non-negative integers or binned for chi2\n",
        "X_chi2 = (X - X.min()).astype(int) # Make features non-negative for chi2 example\n",
        "selector_chi2 = SelectKBest(chi2, k=5)\n",
        "selector_chi2.fit(X_chi2, y)\n",
        "selected_features_chi2 = df_fs.columns[:-1][selector_chi2.get_support()]\n",
        "print(f\"\\nSelected features (Chi-Square): {selected_features_chi2.tolist()}\")\n",
        "\n",
        "# F-score (ANOVA) - for numerical features and categorical target\n",
        "selector_fscore = SelectKBest(f_classif, k=5)\n",
        "selector_fscore.fit(X, y)\n",
        "selected_features_fscore = df_fs.columns[:-1][selector_fscore.get_support()]\n",
        "print(f\"Selected features (F-score): {selected_features_fscore.tolist()}\")\n",
        "\n",
        "# Correlation Coefficient (for numerical features and numerical target - not directly applicable here for classification, but conceptually)\n",
        "# For classification, you'd look at point-biserial correlation or convert target to numerical\n",
        "# For regression, you'd calculate df_fs.corr()['target'].abs().sort_values(ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDT90xoLvjLq",
        "outputId": "f0da9829-2dfc-4ff5-dec9-8e6461ed5f8c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Selected features (Chi-Square): ['feature_1', 'feature_2', 'feature_5', 'feature_7', 'feature_9']\n",
            "Selected features (F-score): ['feature_1', 'feature_2', 'feature_5', 'feature_7', 'feature_9']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. Wrapper Methods"
      ],
      "metadata": {
        "id": "hrAlJI5Fvssy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "estimator = LogisticRegression(solver='liblinear', random_state=42) # A simple estimator\n",
        "selector_rfe = RFE(estimator, n_features_to_select=5, step=1)\n",
        "selector_rfe.fit(X, y)\n",
        "selected_features_rfe = df_fs.columns[:-1][selector_rfe.get_support()]\n",
        "print(f\"\\nSelected features (RFE with Logistic Regression): {selected_features_rfe.tolist()}\")\n",
        "\n",
        "# Genetic Algorithms would typically involve a specialized library like 'TPOT' or custom implementation."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzyqzaYOvp0y",
        "outputId": "85cc8e78-230a-4278-bf08-3f4854c20e83"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Selected features (RFE with Logistic Regression): ['feature_2', 'feature_4', 'feature_5', 'feature_7', 'feature_9']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "c. Embedded Methods"
      ],
      "metadata": {
        "id": "PPWsRih3vyWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X, y)\n",
        "\n",
        "feature_importances = pd.Series(model.feature_importances_, index=df_fs.columns[:-1])\n",
        "selected_features_embedded = feature_importances.nlargest(5).index.tolist()\n",
        "print(f\"\\nSelected features (Embedded - Random Forest Importance):\\n{feature_importances.sort_values(ascending=False).head()}\")\n",
        "print(f\"Top 5 selected features: {selected_features_embedded}\")\n",
        "\n",
        "# For Lasso Regression:\n",
        "# from sklearn.linear_model import Lasso\n",
        "# lasso = Lasso(alpha=0.01) # alpha is regularization strength\n",
        "# lasso.fit(X, y)\n",
        "# non_zero_features = df_fs.columns[:-1][lasso.coef_ != 0].tolist()\n",
        "# print(f\"\\nSelected features (Lasso Regression): {non_zero_features}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b94_oHtKvvaf",
        "outputId": "c4b05067-f135-4fa5-dfd2-1f607a442f9d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Selected features (Embedded - Random Forest Importance):\n",
            "feature_9    0.245956\n",
            "feature_2    0.167019\n",
            "feature_5    0.118863\n",
            "feature_6    0.098968\n",
            "feature_7    0.092285\n",
            "dtype: float64\n",
            "Top 5 selected features: ['feature_9', 'feature_2', 'feature_5', 'feature_6', 'feature_7']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gaXtM9NZv1RR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}